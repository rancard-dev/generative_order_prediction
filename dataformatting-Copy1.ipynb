{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"CSV_Data_For_3.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserID</th>\n",
       "      <th>Order</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>200000000.0</td>\n",
       "      <td>[0,1,0]</td>\n",
       "      <td>[0,0,1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>200000000.0</td>\n",
       "      <td>[0,1,0]</td>\n",
       "      <td>[0,0,1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>200000000.0</td>\n",
       "      <td>[1,0,0]</td>\n",
       "      <td>[0,1,0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>200000000.0</td>\n",
       "      <td>[1,0,0]</td>\n",
       "      <td>[0,0,1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>200000000.0</td>\n",
       "      <td>[1,0,0]</td>\n",
       "      <td>[0,0,1]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        UserID    Order     Time\n",
       "0  200000000.0  [0,1,0]  [0,0,1]\n",
       "1  200000000.0  [0,1,0]  [0,0,1]\n",
       "2  200000000.0  [1,0,0]  [0,1,0]\n",
       "3  200000000.0  [1,0,0]  [0,0,1]\n",
       "4  200000000.0  [1,0,0]  [0,0,1]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "numpy_data = df.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[200000000.0, '[0,1,0]', '[0,0,1]'],\n",
       "       [200000000.0, '[0,1,0]', '[0,0,1]'],\n",
       "       [200000000.0, '[1,0,0]', '[0,1,0]'],\n",
       "       ...,\n",
       "       [5670000000000000.0, '[1,0,0]', '[1,0,0]'],\n",
       "       [5690000000000000.0, '[1,0,0]', '[0,0,1]'],\n",
       "       [5820000000000000.0, '[1,0,0]', '[0,0,1]']], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_data = numpy_data[0:-1]\n",
    "sample_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for val in sample_data:\n",
    "    val[1] = np.array(eval(val[1]))\n",
    "    val[2] = np.array(eval(val[2]))\n",
    "    #print(val[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    " # order_food_dict = {uniq: [[order, time], [order, time],   [order, time], [order, time]],   uniq2: [[order, time], [order, time],   [order, time], [order, time]]}\n",
    "\n",
    "order_food_dict = {}\n",
    "for sample in sample_data:\n",
    "    #print(f\"Key - {sample[0]}     Value - {' '.join([a for a in sample[1].split()[0:-1]])} {sample[2]}\")\n",
    "    #print(\"\\n\")\n",
    "    key = sample[0]\n",
    "    values = sample[1:]\n",
    "    # check if the key is in the dictionary\n",
    "    if order_food_dict.get(key) is not None:\n",
    "         #   - get the value for that key\n",
    "        existing_values = order_food_dict.get(key)\n",
    "        # append new value to existing values\n",
    "        existing_values.append(values)\n",
    "        order_food_dict[key] = existing_values\n",
    "        pass\n",
    "    else:\n",
    "        # create new values array\n",
    "        new_values = []\n",
    "        new_values.append(values)\n",
    "        order_food_dict[key] = new_values\n",
    "    \n",
    "   \n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "WINDOW_SIZE = 1\n",
    "ORDER_SIZE = 3\n",
    "\n",
    "\n",
    "new_dummy_data = []\n",
    "\n",
    "for (k, v) in order_food_dict.items():\n",
    "    customer_orders = order_food_dict.get(k)\n",
    "    dummy_data = np.asarray(customer_orders)\n",
    "    for j in range(len(dummy_data)):\n",
    "        curr = list(dummy_data[j])\n",
    "        if j + 1 < len(dummy_data):\n",
    "            curr.append(dummy_data[j+1][1])\n",
    "            pass\n",
    "        else:\n",
    "            curr.append([0,0,0])\n",
    "\n",
    "        new_dummy_data.append(curr)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_dummy_data\n",
    "x = []\n",
    "y = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, len(new_dummy_data)):\n",
    "    if i + ORDER_SIZE < len(new_dummy_data):\n",
    "        x.append(new_dummy_data[i : i+ORDER_SIZE])\n",
    "        y.append(new_dummy_data[i+ORDER_SIZE][1])\n",
    "        #print(f\"Inputs -> {new_dummy_data[i : i+ORDER_SIZE]} ::::::: Output -> {new_dummy_data[i+ORDER_SIZE][1]} \\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train= np.array(x)\n",
    "y_train = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense,Reshape,LSTM,Dropout,Activation,Bidirectional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(256, input_shape=(3,3,3),activation = 'relu'))\n",
    "model.add(Reshape((3,256*3)))\n",
    "model.add(LSTM(10,return_sequences=True,activation='relu'))\n",
    "model.add(LSTM(10,activation='relu'))\n",
    "model.add(Dense(64))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(32))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(3,activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 3, 3, 256)         1024      \n",
      "_________________________________________________________________\n",
      "reshape (Reshape)            (None, 3, 768)            0         \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 3, 10)             31160     \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 10)                840       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                704       \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 3)                 99        \n",
      "=================================================================\n",
      "Total params: 35,907\n",
      "Trainable params: 35,907\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "115/115 [==============================] - 1s 7ms/step - loss: 0.1060 - acc: 0.9450 - val_loss: 0.1639 - val_acc: 0.9464\n",
      "Epoch 2/70\n",
      "115/115 [==============================] - 1s 7ms/step - loss: 0.1059 - acc: 0.9445 - val_loss: 0.1316 - val_acc: 0.9469\n",
      "Epoch 3/70\n",
      "115/115 [==============================] - 1s 7ms/step - loss: 0.1057 - acc: 0.9441 - val_loss: 0.1404 - val_acc: 0.9440\n",
      "Epoch 4/70\n",
      "115/115 [==============================] - 1s 7ms/step - loss: 0.1052 - acc: 0.9474 - val_loss: 0.1308 - val_acc: 0.9444\n",
      "Epoch 5/70\n",
      "115/115 [==============================] - 1s 7ms/step - loss: 0.1071 - acc: 0.9441 - val_loss: 0.1255 - val_acc: 0.9473\n",
      "Epoch 6/70\n",
      "115/115 [==============================] - 1s 7ms/step - loss: 0.1045 - acc: 0.9464 - val_loss: 0.1399 - val_acc: 0.9501\n",
      "Epoch 7/70\n",
      "115/115 [==============================] - 1s 10ms/step - loss: 0.1041 - acc: 0.9462 - val_loss: 0.1271 - val_acc: 0.9452\n",
      "Epoch 8/70\n",
      "115/115 [==============================] - 1s 7ms/step - loss: 0.1075 - acc: 0.9441 - val_loss: 0.1243 - val_acc: 0.9509\n",
      "Epoch 9/70\n",
      "115/115 [==============================] - 1s 7ms/step - loss: 0.1077 - acc: 0.9462 - val_loss: 0.1223 - val_acc: 0.9469\n",
      "Epoch 10/70\n",
      "115/115 [==============================] - 1s 7ms/step - loss: 0.1031 - acc: 0.9448 - val_loss: 0.1415 - val_acc: 0.9448\n",
      "Epoch 11/70\n",
      "115/115 [==============================] - 1s 7ms/step - loss: 0.1016 - acc: 0.9490 - val_loss: 0.1438 - val_acc: 0.9473\n",
      "Epoch 12/70\n",
      "115/115 [==============================] - 1s 8ms/step - loss: 0.1015 - acc: 0.9481 - val_loss: 0.1385 - val_acc: 0.9509\n",
      "Epoch 13/70\n",
      "115/115 [==============================] - 1s 7ms/step - loss: 0.1014 - acc: 0.9478 - val_loss: 0.1663 - val_acc: 0.9473\n",
      "Epoch 14/70\n",
      "115/115 [==============================] - 1s 7ms/step - loss: 0.1019 - acc: 0.9471 - val_loss: 0.1437 - val_acc: 0.9448\n",
      "Epoch 15/70\n",
      "115/115 [==============================] - 1s 7ms/step - loss: 0.1062 - acc: 0.9483 - val_loss: 0.1381 - val_acc: 0.9485\n",
      "Epoch 16/70\n",
      "115/115 [==============================] - 1s 7ms/step - loss: 0.1003 - acc: 0.9480 - val_loss: 0.1405 - val_acc: 0.9481\n",
      "Epoch 17/70\n",
      "115/115 [==============================] - 1s 7ms/step - loss: 0.1000 - acc: 0.9488 - val_loss: 0.1460 - val_acc: 0.9489\n",
      "Epoch 18/70\n",
      "115/115 [==============================] - 1s 8ms/step - loss: 0.0985 - acc: 0.9481 - val_loss: 0.1720 - val_acc: 0.9485\n",
      "Epoch 19/70\n",
      "115/115 [==============================] - 1s 8ms/step - loss: 0.0983 - acc: 0.9499 - val_loss: 0.1518 - val_acc: 0.9489\n",
      "Epoch 20/70\n",
      "115/115 [==============================] - 1s 7ms/step - loss: 0.1056 - acc: 0.9488 - val_loss: 0.1320 - val_acc: 0.9477\n",
      "Epoch 21/70\n",
      "115/115 [==============================] - 1s 7ms/step - loss: 0.0992 - acc: 0.9502 - val_loss: 0.1553 - val_acc: 0.9473\n",
      "Epoch 22/70\n",
      "115/115 [==============================] - 1s 7ms/step - loss: 0.0991 - acc: 0.9497 - val_loss: 0.1575 - val_acc: 0.9452\n",
      "Epoch 23/70\n",
      "115/115 [==============================] - 1s 7ms/step - loss: 0.0966 - acc: 0.9502 - val_loss: 0.1532 - val_acc: 0.9448\n",
      "Epoch 24/70\n",
      "115/115 [==============================] - 1s 7ms/step - loss: 0.0969 - acc: 0.9487 - val_loss: 0.1547 - val_acc: 0.9481\n",
      "Epoch 25/70\n",
      "115/115 [==============================] - 1s 7ms/step - loss: 0.0969 - acc: 0.9495 - val_loss: 0.1558 - val_acc: 0.9464\n",
      "Epoch 26/70\n",
      "115/115 [==============================] - 1s 7ms/step - loss: 0.0951 - acc: 0.9525 - val_loss: 0.1389 - val_acc: 0.9448\n",
      "Epoch 27/70\n",
      "115/115 [==============================] - 1s 9ms/step - loss: 0.0958 - acc: 0.9523 - val_loss: 0.1683 - val_acc: 0.9493\n",
      "Epoch 28/70\n",
      "115/115 [==============================] - 1s 7ms/step - loss: 0.0943 - acc: 0.9516 - val_loss: 0.1887 - val_acc: 0.9489\n",
      "Epoch 29/70\n",
      "115/115 [==============================] - 1s 7ms/step - loss: 0.0973 - acc: 0.9495 - val_loss: 0.1745 - val_acc: 0.9493\n",
      "Epoch 30/70\n",
      "115/115 [==============================] - 1s 7ms/step - loss: 0.0955 - acc: 0.9513 - val_loss: 0.1560 - val_acc: 0.9501\n",
      "Epoch 31/70\n",
      "115/115 [==============================] - 1s 7ms/step - loss: 0.0949 - acc: 0.9516 - val_loss: 0.1978 - val_acc: 0.9481\n",
      "Epoch 32/70\n",
      "115/115 [==============================] - 1s 7ms/step - loss: 0.0951 - acc: 0.9523 - val_loss: 0.1720 - val_acc: 0.9444\n",
      "Epoch 33/70\n",
      "115/115 [==============================] - 1s 7ms/step - loss: 0.0927 - acc: 0.9548 - val_loss: 0.1753 - val_acc: 0.9501\n",
      "Epoch 34/70\n",
      "115/115 [==============================] - 1s 8ms/step - loss: 0.0953 - acc: 0.9520 - val_loss: 0.1644 - val_acc: 0.9477\n",
      "Epoch 35/70\n",
      "115/115 [==============================] - 1s 7ms/step - loss: 0.0931 - acc: 0.9529 - val_loss: 0.1921 - val_acc: 0.9505\n",
      "Epoch 36/70\n",
      "115/115 [==============================] - 1s 7ms/step - loss: 0.0933 - acc: 0.9523 - val_loss: 0.1737 - val_acc: 0.9473\n",
      "Epoch 37/70\n",
      "115/115 [==============================] - 1s 7ms/step - loss: 0.0927 - acc: 0.9544 - val_loss: 0.1991 - val_acc: 0.9493\n",
      "Epoch 38/70\n",
      "115/115 [==============================] - 1s 7ms/step - loss: 0.0932 - acc: 0.9544 - val_loss: 0.1819 - val_acc: 0.9481\n",
      "Epoch 39/70\n",
      "115/115 [==============================] - 1s 7ms/step - loss: 0.0930 - acc: 0.9532 - val_loss: 0.1736 - val_acc: 0.9489\n",
      "Epoch 40/70\n",
      "115/115 [==============================] - 1s 8ms/step - loss: 0.0917 - acc: 0.9539 - val_loss: 0.1850 - val_acc: 0.9485\n",
      "Epoch 41/70\n",
      "115/115 [==============================] - 1s 7ms/step - loss: 0.0905 - acc: 0.9541 - val_loss: 0.1656 - val_acc: 0.9481\n",
      "Epoch 42/70\n",
      "115/115 [==============================] - 1s 7ms/step - loss: 0.0898 - acc: 0.9551 - val_loss: 0.2024 - val_acc: 0.9489\n",
      "Epoch 43/70\n",
      "115/115 [==============================] - 1s 7ms/step - loss: 0.0919 - acc: 0.9534 - val_loss: 0.1994 - val_acc: 0.9497\n",
      "Epoch 44/70\n",
      "115/115 [==============================] - 1s 7ms/step - loss: 0.0908 - acc: 0.9550 - val_loss: 0.2024 - val_acc: 0.9485\n",
      "Epoch 45/70\n",
      "115/115 [==============================] - 1s 7ms/step - loss: 0.0947 - acc: 0.9499 - val_loss: 0.1716 - val_acc: 0.9456\n",
      "Epoch 46/70\n",
      "115/115 [==============================] - 1s 7ms/step - loss: 0.0895 - acc: 0.9557 - val_loss: 0.1998 - val_acc: 0.9436\n",
      "Epoch 47/70\n",
      "115/115 [==============================] - 1s 7ms/step - loss: 0.0902 - acc: 0.9558 - val_loss: 0.1993 - val_acc: 0.9436\n",
      "Epoch 48/70\n",
      "115/115 [==============================] - 1s 7ms/step - loss: 0.0901 - acc: 0.9558 - val_loss: 0.1902 - val_acc: 0.9481\n",
      "Epoch 49/70\n",
      "115/115 [==============================] - 1s 7ms/step - loss: 0.0938 - acc: 0.9544 - val_loss: 0.1788 - val_acc: 0.9469\n",
      "Epoch 50/70\n",
      "115/115 [==============================] - 1s 7ms/step - loss: 0.0902 - acc: 0.9562 - val_loss: 0.1887 - val_acc: 0.9452\n",
      "Epoch 51/70\n",
      "115/115 [==============================] - 1s 7ms/step - loss: 0.0892 - acc: 0.9578 - val_loss: 0.1916 - val_acc: 0.9473\n",
      "Epoch 52/70\n",
      "115/115 [==============================] - 1s 8ms/step - loss: 0.0908 - acc: 0.9539 - val_loss: 0.1975 - val_acc: 0.9501\n",
      "Epoch 53/70\n",
      "115/115 [==============================] - 1s 7ms/step - loss: 0.0890 - acc: 0.9565 - val_loss: 0.2000 - val_acc: 0.9493\n",
      "Epoch 54/70\n",
      "115/115 [==============================] - 1s 9ms/step - loss: 0.0895 - acc: 0.9562 - val_loss: 0.2123 - val_acc: 0.9493\n",
      "Epoch 55/70\n",
      "115/115 [==============================] - 1s 8ms/step - loss: 0.0886 - acc: 0.9558 - val_loss: 0.1858 - val_acc: 0.9477\n",
      "Epoch 56/70\n",
      "115/115 [==============================] - 1s 8ms/step - loss: 0.0894 - acc: 0.9546 - val_loss: 0.1944 - val_acc: 0.9456\n",
      "Epoch 57/70\n",
      "115/115 [==============================] - 1s 8ms/step - loss: 0.0870 - acc: 0.9558 - val_loss: 0.2132 - val_acc: 0.9452\n",
      "Epoch 58/70\n",
      "115/115 [==============================] - 1s 7ms/step - loss: 0.0880 - acc: 0.9565 - val_loss: 0.2118 - val_acc: 0.9489\n",
      "Epoch 59/70\n",
      "115/115 [==============================] - 1s 7ms/step - loss: 0.0874 - acc: 0.9560 - val_loss: 0.2288 - val_acc: 0.9497\n",
      "Epoch 60/70\n",
      "115/115 [==============================] - 1s 8ms/step - loss: 0.0877 - acc: 0.9576 - val_loss: 0.1922 - val_acc: 0.9448\n",
      "Epoch 61/70\n",
      "115/115 [==============================] - 1s 8ms/step - loss: 0.0901 - acc: 0.9565 - val_loss: 0.2025 - val_acc: 0.9493\n",
      "Epoch 62/70\n",
      "115/115 [==============================] - 1s 7ms/step - loss: 0.0867 - acc: 0.9558 - val_loss: 0.2211 - val_acc: 0.9464\n",
      "Epoch 63/70\n",
      "115/115 [==============================] - 1s 7ms/step - loss: 0.0864 - acc: 0.9557 - val_loss: 0.2286 - val_acc: 0.9464\n",
      "Epoch 64/70\n",
      "115/115 [==============================] - 1s 7ms/step - loss: 0.0876 - acc: 0.9572 - val_loss: 0.2101 - val_acc: 0.9469\n",
      "Epoch 65/70\n",
      "115/115 [==============================] - 1s 10ms/step - loss: 0.0947 - acc: 0.9539 - val_loss: 0.1918 - val_acc: 0.9481\n",
      "Epoch 66/70\n",
      "115/115 [==============================] - 1s 7ms/step - loss: 0.0872 - acc: 0.9567 - val_loss: 0.2516 - val_acc: 0.9456\n",
      "Epoch 67/70\n",
      "115/115 [==============================] - 1s 8ms/step - loss: 0.0855 - acc: 0.9606 - val_loss: 0.2102 - val_acc: 0.9497\n",
      "Epoch 68/70\n",
      "115/115 [==============================] - 1s 7ms/step - loss: 0.0854 - acc: 0.9578 - val_loss: 0.2343 - val_acc: 0.9452\n",
      "Epoch 69/70\n",
      "115/115 [==============================] - 1s 7ms/step - loss: 0.0850 - acc: 0.9569 - val_loss: 0.2275 - val_acc: 0.9477\n",
      "Epoch 70/70\n",
      "115/115 [==============================] - 1s 9ms/step - loss: 0.0929 - acc: 0.9578 - val_loss: 0.2545 - val_acc: 0.9456\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x22eda5f9ec8>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train,y_train,epochs=70,batch_size=50,validation_split=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, 3)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.output_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Dense(64, input_shape=(3,3,3)))\n",
    "model.add(keras.layers.Reshape((3, 64 * 3)))\n",
    "model.add(tf.keras.layers.LSTM(4, return_sequences=True))\n",
    "model.add(tf.keras.layers.LSTM(4))\n",
    "model.add(tf.keras.layers.Dense(3))\n",
    "model.add(tf.keras.layers.Dropout(0.2))\n",
    "model.add(keras.layers.Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(256, input_shape=(3,3,3),activation = 'relu'))\n",
    "model.add(Reshape((3,256*3)))\n",
    "model.add(Bidirectional(LSTM(50,return_sequences=True,activation='relu')))\n",
    "model.add(Bidirectional(LSTM(50,activation='relu')))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(3,activation='sigmoid'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 3, 3, 256)         1024      \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 3, 768)            0         \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, 3, 100)            327600    \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 100)               60400     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 64)                6464      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 3)                 99        \n",
      "=================================================================\n",
      "Total params: 397,667\n",
      "Trainable params: 397,667\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "261/261 [==============================] - 6s 10ms/step - loss: 0.5320 - acc: 0.7412 - val_loss: 0.0694 - val_acc: 0.9620\n",
      "Epoch 2/70\n",
      "261/261 [==============================] - 2s 7ms/step - loss: 0.1268 - acc: 0.9299 - val_loss: 0.0690 - val_acc: 0.9647\n",
      "Epoch 3/70\n",
      "261/261 [==============================] - 2s 8ms/step - loss: 0.1254 - acc: 0.9320 - val_loss: 0.0684 - val_acc: 0.9644\n",
      "Epoch 4/70\n",
      "261/261 [==============================] - 2s 8ms/step - loss: 0.1214 - acc: 0.9338 - val_loss: 0.0684 - val_acc: 0.9647\n",
      "Epoch 5/70\n",
      "261/261 [==============================] - 2s 8ms/step - loss: 0.1198 - acc: 0.9373 - val_loss: 0.0681 - val_acc: 0.9647\n",
      "Epoch 6/70\n",
      "261/261 [==============================] - 2s 8ms/step - loss: 0.1243 - acc: 0.9342 - val_loss: 0.0684 - val_acc: 0.9647\n",
      "Epoch 7/70\n",
      "261/261 [==============================] - 2s 8ms/step - loss: 0.1209 - acc: 0.9358 - val_loss: 0.0684 - val_acc: 0.9647\n",
      "Epoch 8/70\n",
      "261/261 [==============================] - 2s 8ms/step - loss: 0.1222 - acc: 0.9364 - val_loss: 0.0682 - val_acc: 0.9647\n",
      "Epoch 9/70\n",
      "261/261 [==============================] - 2s 8ms/step - loss: 0.1202 - acc: 0.9343 - val_loss: 0.0673 - val_acc: 0.9647\n",
      "Epoch 10/70\n",
      "261/261 [==============================] - 2s 7ms/step - loss: 0.1254 - acc: 0.9329 - val_loss: 0.0674 - val_acc: 0.9654\n",
      "Epoch 11/70\n",
      "261/261 [==============================] - 3s 10ms/step - loss: 0.1186 - acc: 0.9360 - val_loss: 0.0678 - val_acc: 0.9657\n",
      "Epoch 12/70\n",
      "261/261 [==============================] - 3s 10ms/step - loss: 0.1209 - acc: 0.9366 - val_loss: 0.0682 - val_acc: 0.9651\n",
      "Epoch 13/70\n",
      "261/261 [==============================] - 3s 10ms/step - loss: 0.1200 - acc: 0.9348 - val_loss: 0.0665 - val_acc: 0.9654\n",
      "Epoch 14/70\n",
      "261/261 [==============================] - 3s 10ms/step - loss: 0.1195 - acc: 0.9352 - val_loss: 0.0668 - val_acc: 0.9651\n",
      "Epoch 15/70\n",
      "261/261 [==============================] - 3s 10ms/step - loss: 0.1196 - acc: 0.9342 - val_loss: 0.0660 - val_acc: 0.9663\n",
      "Epoch 16/70\n",
      "261/261 [==============================] - 3s 10ms/step - loss: 0.1197 - acc: 0.9370 - val_loss: 0.0662 - val_acc: 0.9669\n",
      "Epoch 17/70\n",
      "261/261 [==============================] - 2s 10ms/step - loss: 0.1196 - acc: 0.9346 - val_loss: 0.0653 - val_acc: 0.9669\n",
      "Epoch 18/70\n",
      "261/261 [==============================] - 3s 10ms/step - loss: 0.1152 - acc: 0.9356 - val_loss: 0.0661 - val_acc: 0.9666\n",
      "Epoch 19/70\n",
      "261/261 [==============================] - 2s 10ms/step - loss: 0.1178 - acc: 0.9375 - val_loss: 0.0659 - val_acc: 0.9675\n",
      "Epoch 20/70\n",
      "261/261 [==============================] - 3s 10ms/step - loss: 0.1084 - acc: 0.9417 - val_loss: 0.0642 - val_acc: 0.9675\n",
      "Epoch 21/70\n",
      "138/261 [==============>...............] - ETA: 1s - loss: 0.1190 - acc: 0.9362"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-9f12d46b10f4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m70\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    853\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2940\u001b[0m       (graph_function,\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2942\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   2943\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1916\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1918\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1919\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    553\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 555\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    556\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit([x_train, x_train],[y_train, y_train],epochs=70,batch_size=50,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_one = keras.layers.Input((3,3,3), name=\"Input_One\")\n",
    "inp_two = keras.layers.Input((3,3,3), name=\"Input_Two\")\n",
    "\n",
    "input_one = Dense(256, activation = 'relu', name=\"Dense_One\")(inp_one)\n",
    "input_two = Dense(128, activation = 'relu')(inp_two)\n",
    "\n",
    "reshape_one = Reshape((3,256*3))(input_one)\n",
    "reshape_two = Reshape((3,128*3))(input_two)\n",
    "\n",
    "bi_lstm = Bidirectional(LSTM(50,return_sequences=True,activation='relu'))(reshape_two)\n",
    "\n",
    "lstm = LSTM(50,return_sequences=True,activation='relu')(reshape_one)\n",
    "\n",
    "\n",
    "out = keras.layers.Concatenate()([bi_lstm, lstm])\n",
    "\n",
    "flatten = keras.layers.Flatten()(out)\n",
    "\n",
    "final = Dense(3,activation='sigmoid')(flatten)\n",
    "\n",
    "model = keras.Model(inputs=[inp_one, inp_two], outputs= final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_15\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Input_Two (InputLayer)          [(None, 3, 3, 3)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Input_One (InputLayer)          [(None, 3, 3, 3)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_63 (Dense)                (None, 3, 3, 128)    512         Input_Two[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "Dense_One (Dense)               (None, 3, 3, 256)    1024        Input_One[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape_46 (Reshape)            (None, 3, 384)       0           dense_63[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "reshape_45 (Reshape)            (None, 3, 768)       0           Dense_One[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_15 (Bidirectional (None, 3, 100)       174000      reshape_46[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lstm_31 (LSTM)                  (None, 3, 50)        163800      reshape_45[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_15 (Concatenate)    (None, 3, 150)       0           bidirectional_15[0][0]           \n",
      "                                                                 lstm_31[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "flatten_4 (Flatten)             (None, 450)          0           concatenate_15[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_64 (Dense)                (None, 3)            1353        flatten_4[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 340,689\n",
      "Trainable params: 340,689\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['acc'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping(patience=20, monitor=\"val_acc\"),\n",
    "    tf.keras.callbacks.ModelCheckpoint(filepath='model.h5'),\n",
    "    tf.keras.callbacks.TensorBoard(log_dir='./logs'),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1305/1305 [==============================] - 6s 4ms/step - loss: 0.1145 - acc: 0.9414 - val_loss: 0.0653 - val_acc: 0.9654\n",
      "Epoch 2/100\n",
      "1305/1305 [==============================] - 5s 4ms/step - loss: 0.1111 - acc: 0.9443 - val_loss: 0.0628 - val_acc: 0.9669\n",
      "Epoch 3/100\n",
      "1305/1305 [==============================] - 5s 4ms/step - loss: 0.1069 - acc: 0.9479 - val_loss: 0.0575 - val_acc: 0.9709\n",
      "Epoch 4/100\n",
      "1305/1305 [==============================] - 5s 4ms/step - loss: 0.1038 - acc: 0.9470 - val_loss: 0.0545 - val_acc: 0.9724\n",
      "Epoch 5/100\n",
      "1305/1305 [==============================] - 6s 4ms/step - loss: 0.1003 - acc: 0.9499 - val_loss: 0.0527 - val_acc: 0.9736\n",
      "Epoch 6/100\n",
      "1305/1305 [==============================] - 6s 5ms/step - loss: 0.0944 - acc: 0.9541 - val_loss: 0.0494 - val_acc: 0.9761\n",
      "Epoch 7/100\n",
      "1305/1305 [==============================] - 7s 5ms/step - loss: 0.0920 - acc: 0.9548 - val_loss: 0.0490 - val_acc: 0.9782\n",
      "Epoch 8/100\n",
      "1305/1305 [==============================] - 6s 5ms/step - loss: 0.0868 - acc: 0.9583 - val_loss: 0.0468 - val_acc: 0.9792\n",
      "Epoch 9/100\n",
      "1305/1305 [==============================] - 6s 4ms/step - loss: 0.0850 - acc: 0.9577 - val_loss: 0.0446 - val_acc: 0.9782\n",
      "Epoch 10/100\n",
      "1305/1305 [==============================] - 6s 5ms/step - loss: 0.0830 - acc: 0.9598 - val_loss: 0.0390 - val_acc: 0.9813\n",
      "Epoch 11/100\n",
      "1305/1305 [==============================] - 6s 5ms/step - loss: 0.0799 - acc: 0.9619 - val_loss: 0.0412 - val_acc: 0.9822\n",
      "Epoch 12/100\n",
      "1305/1305 [==============================] - 6s 5ms/step - loss: 0.0784 - acc: 0.9607 - val_loss: 0.0358 - val_acc: 0.9831\n",
      "Epoch 13/100\n",
      "1305/1305 [==============================] - 5s 4ms/step - loss: 0.0775 - acc: 0.9620 - val_loss: 0.0361 - val_acc: 0.9844\n",
      "Epoch 14/100\n",
      "1305/1305 [==============================] - 5s 4ms/step - loss: 0.0765 - acc: 0.9618 - val_loss: 0.0361 - val_acc: 0.9844\n",
      "Epoch 15/100\n",
      "1305/1305 [==============================] - 6s 4ms/step - loss: 0.0754 - acc: 0.9623 - val_loss: 0.0326 - val_acc: 0.9853\n",
      "Epoch 16/100\n",
      "1305/1305 [==============================] - 7s 5ms/step - loss: 0.0748 - acc: 0.9622 - val_loss: 0.0351 - val_acc: 0.9825\n",
      "Epoch 17/100\n",
      "1305/1305 [==============================] - 6s 5ms/step - loss: 0.0742 - acc: 0.9634 - val_loss: 0.0344 - val_acc: 0.9847\n",
      "Epoch 18/100\n",
      "1305/1305 [==============================] - 6s 5ms/step - loss: 0.0738 - acc: 0.9631 - val_loss: 0.0347 - val_acc: 0.9844\n",
      "Epoch 19/100\n",
      "1305/1305 [==============================] - 6s 5ms/step - loss: 0.0722 - acc: 0.9640 - val_loss: 0.0336 - val_acc: 0.9831\n",
      "Epoch 20/100\n",
      "1305/1305 [==============================] - 6s 5ms/step - loss: 0.0728 - acc: 0.9621 - val_loss: 0.0335 - val_acc: 0.9838\n",
      "Epoch 21/100\n",
      "1305/1305 [==============================] - 6s 5ms/step - loss: 0.0705 - acc: 0.9637 - val_loss: 0.0337 - val_acc: 0.9853\n",
      "Epoch 22/100\n",
      "1305/1305 [==============================] - 6s 5ms/step - loss: 0.0714 - acc: 0.9641 - val_loss: 0.0322 - val_acc: 0.9844\n",
      "Epoch 23/100\n",
      "1305/1305 [==============================] - 6s 5ms/step - loss: 0.0704 - acc: 0.9644 - val_loss: 0.0355 - val_acc: 0.9831\n",
      "Epoch 24/100\n",
      "1305/1305 [==============================] - 6s 5ms/step - loss: 0.0709 - acc: 0.9635 - val_loss: 0.0326 - val_acc: 0.9847\n",
      "Epoch 25/100\n",
      "1305/1305 [==============================] - 6s 5ms/step - loss: 0.0700 - acc: 0.9646 - val_loss: 0.0305 - val_acc: 0.9853\n",
      "Epoch 26/100\n",
      "1305/1305 [==============================] - 6s 5ms/step - loss: 0.0697 - acc: 0.9637 - val_loss: 0.0319 - val_acc: 0.9841\n",
      "Epoch 27/100\n",
      "1305/1305 [==============================] - 7s 5ms/step - loss: 0.0692 - acc: 0.9627 - val_loss: 0.0312 - val_acc: 0.9841\n",
      "Epoch 28/100\n",
      "1305/1305 [==============================] - 6s 5ms/step - loss: 0.0693 - acc: 0.9627 - val_loss: 0.0334 - val_acc: 0.9828\n",
      "Epoch 29/100\n",
      "1305/1305 [==============================] - 7s 5ms/step - loss: 0.0687 - acc: 0.9633 - val_loss: 0.0337 - val_acc: 0.9841\n",
      "Epoch 30/100\n",
      "1305/1305 [==============================] - 7s 5ms/step - loss: 0.0704 - acc: 0.9628 - val_loss: 0.0326 - val_acc: 0.9834\n",
      "Epoch 31/100\n",
      "1305/1305 [==============================] - 7s 5ms/step - loss: 0.0679 - acc: 0.9635 - val_loss: 0.0321 - val_acc: 0.9844\n",
      "Epoch 32/100\n",
      "1305/1305 [==============================] - 7s 5ms/step - loss: 0.0676 - acc: 0.9647 - val_loss: 0.0319 - val_acc: 0.9819\n",
      "Epoch 33/100\n",
      "1305/1305 [==============================] - 7s 5ms/step - loss: 0.0694 - acc: 0.9632 - val_loss: 0.0316 - val_acc: 0.9838\n",
      "Epoch 34/100\n",
      "1305/1305 [==============================] - 7s 5ms/step - loss: 0.0682 - acc: 0.9634 - val_loss: 0.0300 - val_acc: 0.9862\n",
      "Epoch 35/100\n",
      "1305/1305 [==============================] - 6s 5ms/step - loss: 0.0671 - acc: 0.9634 - val_loss: 0.0312 - val_acc: 0.9841\n",
      "Epoch 36/100\n",
      "1305/1305 [==============================] - 6s 5ms/step - loss: 0.0671 - acc: 0.9637 - val_loss: 0.0305 - val_acc: 0.9844\n",
      "Epoch 37/100\n",
      "1305/1305 [==============================] - 6s 5ms/step - loss: 0.0670 - acc: 0.9641 - val_loss: 0.0303 - val_acc: 0.9844\n",
      "Epoch 38/100\n",
      "1305/1305 [==============================] - 6s 5ms/step - loss: 0.0666 - acc: 0.9642 - val_loss: 0.0301 - val_acc: 0.9847\n",
      "Epoch 39/100\n",
      "1305/1305 [==============================] - 6s 4ms/step - loss: 0.0668 - acc: 0.9640 - val_loss: 0.0326 - val_acc: 0.9831\n",
      "Epoch 40/100\n",
      "1305/1305 [==============================] - 6s 5ms/step - loss: 0.0666 - acc: 0.9635 - val_loss: 0.0300 - val_acc: 0.9853\n",
      "Epoch 41/100\n",
      "1305/1305 [==============================] - 6s 4ms/step - loss: 0.0664 - acc: 0.9643 - val_loss: 0.0312 - val_acc: 0.9834\n",
      "Epoch 42/100\n",
      "1305/1305 [==============================] - 6s 5ms/step - loss: 0.0671 - acc: 0.9627 - val_loss: 0.0306 - val_acc: 0.9834\n",
      "Epoch 43/100\n",
      "1305/1305 [==============================] - 7s 5ms/step - loss: 0.0654 - acc: 0.9648 - val_loss: 0.0328 - val_acc: 0.9828\n",
      "Epoch 44/100\n",
      "1305/1305 [==============================] - 6s 5ms/step - loss: 0.0662 - acc: 0.9650 - val_loss: 0.0303 - val_acc: 0.9838\n",
      "Epoch 45/100\n",
      "1305/1305 [==============================] - 6s 5ms/step - loss: 0.0661 - acc: 0.9644 - val_loss: 0.0299 - val_acc: 0.9831\n",
      "Epoch 46/100\n",
      "1305/1305 [==============================] - 7s 5ms/step - loss: 0.0656 - acc: 0.9637 - val_loss: 0.0296 - val_acc: 0.9834\n",
      "Epoch 47/100\n",
      "1305/1305 [==============================] - 6s 5ms/step - loss: 0.0659 - acc: 0.9648 - val_loss: 0.0309 - val_acc: 0.9847\n",
      "Epoch 48/100\n",
      "1305/1305 [==============================] - 7s 5ms/step - loss: 0.0658 - acc: 0.9646 - val_loss: 0.0293 - val_acc: 0.9834\n",
      "Epoch 49/100\n",
      "1305/1305 [==============================] - 6s 5ms/step - loss: 0.0656 - acc: 0.9656 - val_loss: 0.0321 - val_acc: 0.9841\n",
      "Epoch 50/100\n",
      "1305/1305 [==============================] - 6s 5ms/step - loss: 0.0662 - acc: 0.9647 - val_loss: 0.0291 - val_acc: 0.9841\n",
      "Epoch 51/100\n",
      "1305/1305 [==============================] - 6s 5ms/step - loss: 0.0658 - acc: 0.9646 - val_loss: 0.0298 - val_acc: 0.9834\n",
      "Epoch 52/100\n",
      "1305/1305 [==============================] - 6s 5ms/step - loss: 0.0654 - acc: 0.9622 - val_loss: 0.0306 - val_acc: 0.9825\n",
      "Epoch 53/100\n",
      "1305/1305 [==============================] - 6s 5ms/step - loss: 0.0667 - acc: 0.9653 - val_loss: 0.0311 - val_acc: 0.9838\n",
      "Epoch 54/100\n",
      "1305/1305 [==============================] - 6s 5ms/step - loss: 0.0651 - acc: 0.9633 - val_loss: 0.0296 - val_acc: 0.9853\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fef601303d0>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit([x_train, x_train],y_train,epochs=100,batch_size=10,validation_split=0.2, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_inp = x_train[0].reshape(-1,3,3,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model_two.predict([test_inp, test_inp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_two = keras.models.load_model('model.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
